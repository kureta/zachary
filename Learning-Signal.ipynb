{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.datasets import AtemporalDataset\n",
    "from zachary.utils import get_torch_device, get_num_trainable_params\n",
    "from zachary.weight_initializers import initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = get_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AtemporalDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = librosa.time_to_frames(10, sr=44100, hop_length=512, n_fft=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.imshow(dataset[:dur].numpy().T, aspect='auto', origin='lower')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_signal(S, num_iters=15):\n",
    "    S_T = S.T\n",
    "\n",
    "    # Retrieve phase information\n",
    "    phase = 2 * np.pi * np.random.random_sample(S_T.shape) - np.pi\n",
    "    signal = None\n",
    "    for idx in range(num_iters):\n",
    "        D = S_T * np.exp(1j * phase)\n",
    "        signal = librosa.istft(D, hop_length=512, win_length=1024)\n",
    "        # don't calculate phase during the last iteration, because it will not be used.\n",
    "        if idx < num_iters - 1:\n",
    "            phase = np.angle(librosa.stft(signal, n_fft=1024, hop_length=512))\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = stft_to_signal(dataset[:dur].numpy(), num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(sig)/44100, len(sig))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, sig)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sig, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Linear(513, 256)\n",
    "        self.c2 = nn.Linear(256, 128)\n",
    "        self.c3 = nn.Linear(128, 64)\n",
    "        self.c4 = nn.Linear(64, 32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.c1(x))\n",
    "        z = F.relu(self.c2(z))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = self.c4(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Linear(32, 64)\n",
    "        self.c2 = nn.Linear(64, 128)\n",
    "        self.c3 = nn.Linear(128, 256)\n",
    "        self.c4 = nn.Linear(256, 513)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.c1(x))\n",
    "        z = F.relu(self.c2(z))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = self.c4(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "initialize_model(model)\n",
    "print('\\t', get_num_trainable_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.train()\n",
    "for i in range(2):\n",
    "    batch = 1\n",
    "    with tqdm_notebook(total=len(dataset)) as pbar:\n",
    "        for absolute in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            cc = absolute.to(DEVICE)\n",
    "            loss = loss_fn(model(cc), cc)\n",
    "\n",
    "            pbar.set_description(f'Epoch: {i + 1} - loss: {loss.data.cpu().numpy():.2E}')\n",
    "            pbar.update(absolute.shape[0])\n",
    "\n",
    "            batch += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.datasets import load_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[:dur].unsqueeze(0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_hat = model(sample)\n",
    "\n",
    "sample_hat = sample_hat.squeeze(0).cpu()\n",
    "sample_hat_np = sample_hat.squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_hat = stft_to_signal(sample_hat_np, num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(sig)/44100, len(sig))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, signal_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bspline(cv, n=100, degree=3, periodic=False):\n",
    "    # If periodic, extend the point array by count+degree+1\n",
    "    if degree < 1:\n",
    "        raise ValueError('degree cannot be less then 1!')\n",
    "    count = len(cv)\n",
    "\n",
    "    if periodic:\n",
    "        factor, fraction = divmod(count + degree + 1, count)\n",
    "        cv = np.concatenate((cv,) * factor + (cv[:fraction],))\n",
    "        count = len(cv)\n",
    "\n",
    "    # If opened, prevent degree from exceeding count-1\n",
    "    else:\n",
    "        if count < degree + 1:\n",
    "            raise ValueError('number of cvs must be higher than degree + 1')\n",
    "\n",
    "    # Calculate knot vector\n",
    "    if periodic:\n",
    "        kv = np.arange(0 - degree, count + degree + degree - 1, dtype='int')\n",
    "    else:\n",
    "        kv = np.array([0] * degree + list(range(count - degree + 1)) + [count - degree] * degree, dtype='int')\n",
    "\n",
    "    # Calculate query range\n",
    "    u = np.linspace(periodic, (count - degree), n)\n",
    "\n",
    "    # Calculate result\n",
    "    arange = np.arange(len(u))\n",
    "    points = np.zeros((len(u), cv.shape[1]))\n",
    "    for i in range(cv.shape[1]):\n",
    "        points[arange, i] = si.splev(u, (kv, cv[:, i], degree))\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def sample_z(z_dims, mean, std, num_cv, resolution, degree, is_periodic):\n",
    "    # Generates splines of random lengths in z_dims dimensions\n",
    "    # num_cv = np.random.randint(64, 128)\n",
    "    cv = np.random.normal(mean, std, (num_cv, z_dims))\n",
    "    num_points = num_cv * resolution\n",
    "    spline = bspline(cv, num_points, degree, is_periodic)\n",
    "    return spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = sample_z(model.encoder.c4.out_features, 0., 1., 100, 25, 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_t = torch.from_numpy(zs.astype('float32')).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = model.decoder(zs_t)\n",
    "\n",
    "y_hat = y.cpu()\n",
    "y_hat_np = y_hat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hat = stft_to_signal(y_hat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(s_hat)/44100, len(s_hat))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, s_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(s_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachary-ipyk",
   "language": "python",
   "name": "zachary-ipyk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
