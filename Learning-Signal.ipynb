{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.datasets import AtemporalDataset, GANDataset, f0_from_stft_frame, pseudo_one_hot\n",
    "from zachary.utils import get_torch_device, get_num_trainable_params\n",
    "from zachary.weight_initializers import initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = get_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AtemporalDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape, dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = librosa.time_to_frames(10, sr=44100, hop_length=512, n_fft=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, i):\n",
    "    specgram = np.empty((size, dataset[0][i].shape[0]), dtype='float32')\n",
    "    for idx in range(size):\n",
    "        specgram[idx] = dataset[idx][i]\n",
    "    return specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4) \n",
    "specgram = get_data(dur, 0)\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.imshow(specgram.T, aspect='auto', origin='lower')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "specgram = get_data(dur, 1)\n",
    "    \n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.imshow(specgram.T, aspect='auto', origin='lower')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_signal(S, num_iters=15):\n",
    "    S_T = S.T\n",
    "\n",
    "    # Retrieve phase information\n",
    "    phase = 2 * np.pi * np.random.random_sample(S_T.shape) - np.pi\n",
    "    signal = None\n",
    "    for idx in range(num_iters):\n",
    "        D = S_T * np.exp(1j * phase)\n",
    "        signal = librosa.istft(D, hop_length=512, win_length=1024)\n",
    "        # don't calculate phase during the last iteration, because it will not be used.\n",
    "        if idx < num_iters - 1:\n",
    "            phase = np.angle(librosa.stft(signal, n_fft=1024, hop_length=512))\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = stft_to_signal(get_data(dur, 0), num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(sig)/44100, len(sig))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, sig)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sig, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Linear(513, 256)\n",
    "        self.c2 = nn.Linear(256, 128)\n",
    "        self.c3 = nn.Linear(128, 64)\n",
    "        self.c4 = nn.Linear(64, 32)\n",
    "        self.c5 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.c1(x))\n",
    "        z = F.relu(self.c2(z))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = F.relu(self.c4(z))\n",
    "        z = self.c5(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Linear(4+128, 32)\n",
    "        self.c2 = nn.Linear(32, 64)\n",
    "        self.c3 = nn.Linear(64, 128)\n",
    "        self.c4 = nn.Linear(128, 256)\n",
    "        self.c5 = nn.Linear(256, 513)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.c1(x))\n",
    "        z = F.relu(self.c2(z))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = F.relu(self.c4(z))\n",
    "        z = self.c5(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()  \n",
    "\n",
    "    def forward(self, x, f0):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(torch.cat([z, f0], 1))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "initialize_model(model)\n",
    "print('\\t', get_num_trainable_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.train()\n",
    "for i in range(2):\n",
    "    batch = 1\n",
    "    with tqdm_notebook(total=len(dataset)) as pbar:\n",
    "        for absolute, f0 in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            absolute = absolute.to(DEVICE)\n",
    "            f0 = f0.to(DEVICE)\n",
    "            loss = loss_fn(model(absolute, f0), absolute)\n",
    "\n",
    "            pbar.set_description(f'Epoch: {i + 1} - loss: {loss.data.cpu().numpy():.2E}')\n",
    "            pbar.update(absolute.shape[0])\n",
    "\n",
    "            batch += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.datasets import load_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.from_numpy(get_data(dur, 0)).to(DEVICE)\n",
    "pitches = torch.from_numpy(get_data(dur, 1)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape, pitches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_hat = model(sample, pitches)\n",
    "\n",
    "sample_hat = sample_hat.cpu()\n",
    "sample_hat_np = sample_hat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_hat = stft_to_signal(sample_hat_np, num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(sig)/44100, len(sig))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, signal_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bspline(cv, n=100, degree=3, periodic=False):\n",
    "    # If periodic, extend the point array by count+degree+1\n",
    "    if degree < 1:\n",
    "        raise ValueError('degree cannot be less then 1!')\n",
    "    count = len(cv)\n",
    "\n",
    "    if periodic:\n",
    "        factor, fraction = divmod(count + degree + 1, count)\n",
    "        cv = np.concatenate((cv,) * factor + (cv[:fraction],))\n",
    "        count = len(cv)\n",
    "\n",
    "    # If opened, prevent degree from exceeding count-1\n",
    "    else:\n",
    "        if count < degree + 1:\n",
    "            raise ValueError('number of cvs must be higher than degree + 1')\n",
    "\n",
    "    # Calculate knot vector\n",
    "    if periodic:\n",
    "        kv = np.arange(0 - degree, count + degree + degree - 1, dtype='int')\n",
    "    else:\n",
    "        kv = np.array([0] * degree + list(range(count - degree + 1)) + [count - degree] * degree, dtype='int')\n",
    "\n",
    "    # Calculate query range\n",
    "    u = np.linspace(periodic, (count - degree), n)\n",
    "\n",
    "    # Calculate result\n",
    "    arange = np.arange(len(u))\n",
    "    points = np.zeros((len(u), cv.shape[1]))\n",
    "    for i in range(cv.shape[1]):\n",
    "        points[arange, i] = si.splev(u, (kv, cv[:, i], degree))\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def sample_z(z_dims, mean, std, num_cv, resolution, degree, is_periodic):\n",
    "    # Generates splines of random lengths in z_dims dimensions\n",
    "    # num_cv = np.random.randint(64, 128)\n",
    "    cv = np.random.normal(mean, std, (num_cv, z_dims))\n",
    "    num_points = num_cv * resolution\n",
    "    spline = bspline(cv, num_points, degree, is_periodic)\n",
    "    return spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 25\n",
    "num_cv = dur // resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = sample_z(model.encoder.c5.out_features, 0., 2., num_cv, resolution, 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_t = torch.from_numpy(zs.astype('float32')).to(DEVICE)\n",
    "pitches = torch.from_numpy(get_data(zs_t.shape[0], 1)).to(DEVICE)\n",
    "#pitches = torch.zeros_like(pitches)\n",
    "#pitches[:, 60] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = model.decoder(torch.cat([zs_t, pitches], 1))\n",
    "\n",
    "y_hat = y.cpu()\n",
    "y_hat_np = y_hat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hat = stft_to_signal(y_hat_np, num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(s_hat)/44100, len(s_hat))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, s_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(s_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_dataset = GANDataset(dataset, model.encoder, example_length=64, stft_hop_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.ConvTranspose1d(128, 64, 4, 4),\n",
    "            nn.BatchNorm1d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose1d(64, 32, 4, 4),\n",
    "            nn.BatchNorm1d(32, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose1d(32, 16, 4, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.conv_blocks(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 4, 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.BatchNorm1d(32, 0.8),\n",
    "            \n",
    "            nn.Conv1d(32, 64, 4, 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.BatchNorm1d(64, 0.8),\n",
    "            \n",
    "            nn.Conv1d(64, 128, 4, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validities = self.conv_blocks(img)\n",
    "        return validities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "gen.to(DEVICE)\n",
    "disc.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = torch.ones(1, 128, 4)\n",
    "asd.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(asd).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc(gen(asd)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwe = gan_dataset[0].transpose(0, 1).to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    qwe = model.encoder(qwe).transpose(0, 1)\n",
    "\n",
    "disc(qwe.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachary-ipyk",
   "language": "python",
   "name": "zachary-ipyk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
