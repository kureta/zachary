{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.datasets import AtemporalDataset, GANDataset, f0_midi_from_stft_frame, pseudo_one_hot, sample_z\n",
    "from zachary.utils import get_torch_device, get_num_trainable_params\n",
    "from zachary.weight_initializers import initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "DEVICE = get_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AtemporalDataset(audio_directory='/home/kureta/Music/chorales/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape, dataset[0][1].shape, dataset[0][2].shape, dataset[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = partial(librosa.time_to_frames, sr=44100, hop_length=512, n_fft=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4) \n",
    "specgram = dataset[:dur(10)]\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.imshow(specgram.t(), aspect='auto', origin='lower')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_signal(S, num_iters=15):\n",
    "    S_T = S.T\n",
    "\n",
    "    # Retrieve phase information\n",
    "    phase = 2 * np.pi * np.random.random_sample(S_T.shape) - np.pi\n",
    "    signal = None\n",
    "    for idx in range(num_iters):\n",
    "        D = S_T * np.exp(1j * phase)\n",
    "        signal = librosa.istft(D, hop_length=512, win_length=1024)\n",
    "        # don't calculate phase during the last iteration, because it will not be used.\n",
    "        if idx < num_iters - 1:\n",
    "            phase = np.angle(librosa.stft(signal, n_fft=1024, hop_length=512))\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = stft_to_signal((dataset[:dur(10)] * dataset.maxima).numpy(), num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(sig)/44100, len(sig))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, sig)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sig, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Linear(513, 256)\n",
    "        self.c2 = nn.Linear(256, 128)\n",
    "        self.c3 = nn.Linear(128, 64)\n",
    "        self.c4 = nn.Linear(64, 8+87+11+11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.c1(x))\n",
    "        z = F.relu(self.c2(z))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = self.c4(z)\n",
    "        \n",
    "        return z[:, :8], F.sigmoid(z[:, 8:8+87]), F.sigmoid(z[:, 8+87:8+87+11]), F.sigmoid(z[:, 8+87+11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed1 = nn.Embedding(87, 8)\n",
    "        self.embed2 = nn.Embedding(11, 4)\n",
    "        self.embed3 = nn.Embedding(11, 4)\n",
    "        \n",
    "        self.c2 = nn.Linear(8+8+4+4, 64)\n",
    "        self.c3 = nn.Linear(64, 128)\n",
    "        self.c4 = nn.Linear(128, 256)\n",
    "        self.c5 = nn.Linear(256, 513)\n",
    "        \n",
    "    def forward(self, x, f0, conf, loud):\n",
    "        f0 = F.relu(self.embed1(f0).squeeze(1))\n",
    "        conf = F.relu(self.embed2(conf).squeeze(1))\n",
    "        loud = F.relu(self.embed3(loud).squeeze(1))\n",
    "        z = F.relu(self.c2(torch.cat([x, f0, conf, loud], 1)))\n",
    "        z = F.relu(self.c3(z))\n",
    "        z = F.relu(self.c4(z))\n",
    "        z = self.c5(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()  \n",
    "\n",
    "    def forward(self, x, f0, conf, loud):\n",
    "        z, f0_hat, conf_hat, loud_hat = self.encoder(x)\n",
    "        y = self.decoder(z, f0, conf, loud)\n",
    "        \n",
    "        return y, f0_hat, conf_hat, loud_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "initialize_model(model)\n",
    "print('\\t', get_num_trainable_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x, x_hat, f0, conf, loud, f0_hat, conf_hat, loud_hat):\n",
    "    x_loss = F.mse_loss(x_hat, x)\n",
    "    f0_loss = F.cross_entropy(f0_hat, f0.squeeze(1))\n",
    "    conf_loss = F.cross_entropy(conf_hat, conf.squeeze(1))\n",
    "    loud_loss = F.cross_entropy(loud_hat, loud.squeeze(1))\n",
    "    return x_loss + f0_loss + conf_loss + loud_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.train()\n",
    "for i in range(5):\n",
    "    batch = 1\n",
    "    with tqdm_notebook(total=len(dataset)) as pbar:\n",
    "        for absolute, f0, conf, loud in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            absolute = absolute.to(DEVICE)\n",
    "            f0 = f0.to(DEVICE)\n",
    "            conf = conf.to(DEVICE)\n",
    "            loud = loud.to(DEVICE)\n",
    "            x_hat, f0_hat, conf_hat, loud_hat = model(absolute, f0, conf, loud)\n",
    "            loss = loss_fn(absolute, x_hat, f0, conf, loud, f0_hat, conf_hat, loud_hat)\n",
    "\n",
    "            pbar.set_description(f'Epoch: {i + 1} - loss: {loss.data.cpu().numpy():.2E}')\n",
    "            pbar.update(absolute.shape[0])\n",
    "\n",
    "            batch += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.zeros((dur(10), 513))\n",
    "f0s = torch.zeros(dur(10), 1, dtype=torch.int64)\n",
    "confidences = torch.zeros(dur(10), 1, dtype=torch.int64)\n",
    "loudnesses = torch.zeros(dur(10), 1, dtype=torch.int64)\n",
    "for idx in range(dur(10)):\n",
    "    sample[idx] = dataset[idx][0]\n",
    "    f0s[idx] = dataset[idx][1]\n",
    "    confidences[idx] = dataset[idx][2]\n",
    "    loudnesses[idx] = dataset[idx][3]\n",
    "sample = sample.to(DEVICE)\n",
    "f0s = f0s.to(DEVICE)\n",
    "confidences = confidences.to(DEVICE)\n",
    "loudnesses = loudnesses.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape, f0s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_hat, _, _, _ = model(sample, f0s, confidences, loudnesses)\n",
    "\n",
    "sample_hat = sample_hat.cpu() * dataset.maxima\n",
    "sample_hat_np = sample_hat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_hat = stft_to_signal(sample_hat_np, num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(signal_hat)/44100, len(signal_hat))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, signal_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 50\n",
    "num_cv = dur(10) // resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = sample_z(8, 0., 1., num_cv, resolution, 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_t = torch.from_numpy(zs.astype('float32')).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = torch.zeros((zs_t.shape[0], f0s.shape[1]), dtype=torch.int64)\n",
    "constant[:] = 10\n",
    "constant = constant.to(DEVICE)\n",
    "\n",
    "constant1 = torch.zeros((zs_t.shape[0], confidences.shape[1]), dtype=torch.int64)\n",
    "constant1[:] = 5\n",
    "constant1 = constant1.to(DEVICE)\n",
    "\n",
    "constant2 = torch.zeros((zs_t.shape[0], loudnesses.shape[1]), dtype=torch.int64)\n",
    "constant2[:] = 4\n",
    "constant2 = constant2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = model.decoder(zs_t, constant, constant1, constant2)\n",
    "\n",
    "y_hat = y.cpu() * dataset.maxima\n",
    "y_hat_np = y_hat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hat = stft_to_signal(y_hat_np, num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 4)\n",
    "t = np.linspace(0, len(s_hat)/44100, len(s_hat))\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "ax1.plot(t, s_hat)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(s_hat, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_dataset = GANDataset(dataset, model.encoder, example_length=64, stft_hop_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.ConvTranspose1d(128, 64, 4, 4),\n",
    "            nn.BatchNorm1d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose1d(64, 32, 4, 4),\n",
    "            nn.BatchNorm1d(32, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose1d(32, 16, 4, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.conv_blocks(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 4, 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.BatchNorm1d(32, 0.8),\n",
    "            \n",
    "            nn.Conv1d(32, 64, 4, 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.BatchNorm1d(64, 0.8),\n",
    "            \n",
    "            nn.Conv1d(64, 128, 4, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validities = self.conv_blocks(img)\n",
    "        return validities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "gen.to(DEVICE)\n",
    "disc.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = torch.ones(1, 128, 4)\n",
    "asd.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(asd).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc(gen(asd)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwe = gan_dataset[0].transpose(0, 1).to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    qwe = model.encoder(qwe).transpose(0, 1)\n",
    "\n",
    "disc(qwe.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachary-ipyk",
   "language": "python",
   "name": "zachary-ipyk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
