{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.preprocess.datasets import AtemporalDataset, TemporalDataset\n",
    "from zachary.preprocess.base import Configuration\n",
    "from zachary.weight_initializers import initialize_model\n",
    "from zachary.utils import get_torch_device, get_num_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(spect):\n",
    "    plt.rcParams['figure.figsize'] = (19, 6)\n",
    "\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    ax1.imshow(spect, aspect='auto', interpolation='none', origin='lower')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Encoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Encoder, self).__init__()\n",
    "            \n",
    "            self.conv1 = nn.Conv1d(\n",
    "                in_channels=513,\n",
    "                out_channels=256,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            )\n",
    "            self.conv2 = nn.Conv1d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "            self.conv3 = nn.Conv1d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1)\n",
    "            \n",
    "            self.norm1 = nn.InstanceNorm1d(num_features=256)\n",
    "            self.norm2 = nn.InstanceNorm1d(num_features=128)\n",
    "            self.norm3 = nn.InstanceNorm1d(num_features=64)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            z = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "            z = F.leaky_relu(self.norm2(self.conv2(z)))\n",
    "            z = F.leaky_relu(self.norm3(self.conv3(z)))\n",
    "            \n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels=64):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.InstanceNorm1d(num_features=num_channels)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z_hat = F.leaky_relu(self.norm(self.conv(z)))\n",
    "        return z + z_hat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_channels=64, num_blocks=6):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            self.blocks.append(ResidualBlock(num_channels))\n",
    "    \n",
    "    def forward(self, z):\n",
    "        for block in self.blocks:\n",
    "            z = block(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "        \n",
    "    def to(self, *args, **kwargs):\n",
    "        super(Transformer, self).to(*args, **kwargs)\n",
    "        for block in self.blocks:\n",
    "            block.to(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Decoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Decoder, self).__init__()\n",
    "            \n",
    "            self.conv1 = nn.ConvTranspose1d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "            self.conv2 = nn.ConvTranspose1d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "            self.conv3 = nn.ConvTranspose1d(\n",
    "                in_channels=256,\n",
    "                out_channels=513,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            )\n",
    "            self.norm1 = nn.InstanceNorm1d(num_features=128)\n",
    "            self.norm2 = nn.InstanceNorm1d(num_features=256)\n",
    "        \n",
    "        def forward(self, z):\n",
    "            y_hat = F.leaky_relu(self.norm1(self.conv1(z)))\n",
    "            y_hat = F.leaky_relu(self.norm2(self.conv2(y_hat)))\n",
    "            y_hat = F.sigmoid(self.conv3(y_hat))\n",
    "            \n",
    "            return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "                in_channels=256,\n",
    "                out_channels=512,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "                in_channels=512,\n",
    "                out_channels=1,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            )\n",
    "        \n",
    "        self.norm1 = nn.InstanceNorm2d(num_features=64)\n",
    "        self.norm2 = nn.InstanceNorm2d(num_features=128)\n",
    "        self.norm3 = nn.InstanceNorm2d(num_features=256)\n",
    "        self.norm4 = nn.InstanceNorm2d(num_features=512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        d = F.leaky_relu(self.norm2(self.conv2(d)))\n",
    "        d = F.leaky_relu(self.norm3(self.conv3(d)))\n",
    "        d = F.leaky_relu(self.norm4(self.conv4(d)))\n",
    "        d = F.sigmoid(self.conv5(d))\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.transformer = Transformer()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_hat = self.transformer(z)\n",
    "        y_hat = self.decoder(z_hat)\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    def to(self, *args, **kwargs):\n",
    "        super(Generator, self).to(*args, **kwargs)\n",
    "        self.encoder.to(*args, **kwargs)\n",
    "        self.transformer.to(*args, **kwargs)\n",
    "        self.decoder.to(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_b = Generator()\n",
    "gen_b_a = Generator()\n",
    "disc_a = Discriminator()\n",
    "disc_b = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_gen = torch.optim.Adam(chain(gen_a_b.parameters(), gen_b_a.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_disc_a = torch.optim.Adam(disc_a.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_disc_b = torch.optim.Adam(disc_b.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = get_torch_device()\n",
    "EPOCHS = 2\n",
    "\n",
    "conf_a = Configuration(audio_dir='/home/kureta/Music/Palestrina - Missa Pap√¶ Marcelli - Ensemble Officium, Wilfried Rombach/')\n",
    "dataset_a = TemporalDataset(conf=conf_a, example_length=32, example_hop_length=4)\n",
    "data_loader_a = DataLoader(dataset_a, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "conf_b = Configuration(audio_dir='/home/kureta/Music/gertrude/')\n",
    "dataset_b = TemporalDataset(conf=conf_b, example_length=32, example_hop_length=4)\n",
    "data_loader_b = DataLoader(dataset_b, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_b.train()\n",
    "gen_b_a.train()\n",
    "disc_a.train()\n",
    "disc_b.train()\n",
    "gen_a_b.to(DEVICE)\n",
    "gen_b_a.to(DEVICE)\n",
    "disc_a.to(DEVICE)\n",
    "disc_b.to(DEVICE)\n",
    "\n",
    "enc = Encoder()\n",
    "trans = Transformer()\n",
    "dec = Decoder()\n",
    "\n",
    "enc.to(DEVICE)\n",
    "dec.to(DEVICE)\n",
    "trans.to(DEVICE)\n",
    "\n",
    "for i in range(1):\n",
    "    for example_a, example_b in zip(data_loader_a, data_loader_b):\n",
    "        example_a = example_a.to(DEVICE)\n",
    "        example_b = example_b.to(DEVICE)\n",
    "        b_hat = gen_a_b(example_a)\n",
    "        a_hat = gen_b_a(example_b)\n",
    "        real_a = disc_a(example_a.unsqueeze(1))\n",
    "        fake_a = disc_a(a_hat.unsqueeze(1))\n",
    "        real_b = disc_b(example_b.unsqueeze(1))\n",
    "        fake_b = disc_b(b_hat.unsqueeze(1))\n",
    "        break\n",
    "#         print(example_a.shape, example_b.shape)\n",
    "#         break\n",
    "#         spectrum = spectrum.to(DEVICE)\n",
    "#         pitch = pitch.to(DEVICE).unsqueeze(1)\n",
    "#         confidence = confidence.to(DEVICE).unsqueeze(1)\n",
    "#         loudness = loudness.to(DEVICE).unsqueeze(1)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         spectrum_hat = model(spectrum, pitch, confidence, loudness)\n",
    "#         loss = loss_function(spectrum_hat, spectrum)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         pbar.set_description(\n",
    "#             f'Epoch: {i + 1} - loss: {loss.data.cpu().numpy():.2E}')\n",
    "#         pbar.update(spectrum.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat.shape, example_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_a.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder and encoder are not symmetrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachary-venv",
   "language": "python",
   "name": "zachary-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
