{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.preprocess.datasets import AtemporalDataset, TemporalDataset, AtemporalMidiDataset, TemporalMidiDataset\n",
    "from zachary.preprocess.base import Configuration\n",
    "from zachary.preprocess.utils import load_audio_file, spectrum_from_signal\n",
    "from zachary.weight_initializers import initialize_model\n",
    "from zachary.utils import get_torch_device, get_num_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(spect):\n",
    "    plt.rcParams['figure.figsize'] = (19, 6)\n",
    "\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    ax1.imshow(spect, aspect='auto', interpolation='none', origin='lower')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Encoder(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(Encoder, self).__init__()\n",
    "            \n",
    "            self.conv1 = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=256,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            )\n",
    "            self.conv2 = nn.Conv1d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "            self.conv3 = nn.Conv1d(\n",
    "                in_channels=128,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1)\n",
    "            \n",
    "            self.norm1 = nn.InstanceNorm1d(num_features=256)\n",
    "            self.norm2 = nn.InstanceNorm1d(num_features=128)\n",
    "            self.norm3 = nn.InstanceNorm1d(num_features=64)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            z = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "            z = F.leaky_relu(self.norm2(self.conv2(z)))\n",
    "            z = F.leaky_relu(self.norm3(self.conv3(z)))\n",
    "\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels=64):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=num_channels // 2,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=num_channels // 2,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        self.norm1 = nn.InstanceNorm1d(num_features=num_channels * 2)\n",
    "        self.norm2 = nn.InstanceNorm1d(num_features=num_channels)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z_hat = F.leaky_relu(self.norm1(self.conv1(z)))\n",
    "        z_hat = F.leaky_relu(self.norm2(self.conv2(z_hat)))\n",
    "        return z + z_hat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_channels, num_blocks):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            self.blocks.append(ResidualBlock(num_channels))\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z_hat = z\n",
    "        for block in self.blocks:\n",
    "            z_hat = block(z_hat)\n",
    "\n",
    "        return z_hat\n",
    "        \n",
    "    def to(self, *args, **kwargs):\n",
    "        super(Transformer, self).to(*args, **kwargs)\n",
    "        for block in self.blocks:\n",
    "            block.to(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Decoder(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(Decoder, self).__init__()\n",
    "            \n",
    "            self.conv1 = nn.ConvTranspose1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=512,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1\n",
    "            )\n",
    "            self.conv2 = nn.ConvTranspose1d(\n",
    "                in_channels=512,\n",
    "                out_channels=1024,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1\n",
    "            )\n",
    "            self.conv3 = nn.ConvTranspose1d(\n",
    "                in_channels=1024,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            )\n",
    "            self.norm1 = nn.InstanceNorm1d(num_features=512)\n",
    "            self.norm2 = nn.InstanceNorm1d(num_features=1024)\n",
    "        \n",
    "        def forward(self, z):\n",
    "            y_hat = F.leaky_relu(self.norm1(self.conv1(z)))\n",
    "            y_hat = F.leaky_relu(self.norm2(self.conv2(y_hat)))\n",
    "            y_hat = self.conv3(y_hat)\n",
    "\n",
    "            return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, a_channels, b_channels, z_channels, transformer_depth):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(a_channels, z_channels)\n",
    "        self.transformer = Transformer(z_channels, transformer_depth)\n",
    "        self.decoder = Decoder(z_channels, b_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_hat = self.transformer(z)\n",
    "        y_hat = self.decoder(z_hat)\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    def to(self, *args, **kwargs):\n",
    "        super(Generator, self).to(*args, **kwargs)\n",
    "        self.encoder.to(*args, **kwargs)\n",
    "        self.transformer.to(*args, **kwargs)\n",
    "        self.decoder.to(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=1024,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "                in_channels=1024,\n",
    "                out_channels=512,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "        self.conv3 = nn.Conv1d(\n",
    "                in_channels=512,\n",
    "                out_channels=1,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            )\n",
    "#         self.conv4 = nn.Conv2d(\n",
    "#                 in_channels=256,\n",
    "#                 out_channels=512,\n",
    "#                 kernel_size=3,\n",
    "#                 stride=2,\n",
    "#                 padding=1\n",
    "#             )\n",
    "#         self.conv5 = nn.Conv2d(\n",
    "#                 in_channels=512,\n",
    "#                 out_channels=1,\n",
    "#                 kernel_size=3,\n",
    "#                 stride=2,\n",
    "#                 padding=1\n",
    "#             )\n",
    "        \n",
    "        self.norm1 = nn.InstanceNorm1d(num_features=64)\n",
    "        self.norm2 = nn.InstanceNorm1d(num_features=128)\n",
    "        self.norm3 = nn.InstanceNorm1d(num_features=256)\n",
    "#         self.norm4 = nn.InstanceNorm2d(num_features=512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        d = F.leaky_relu(self.norm2(self.conv2(d)))\n",
    "#         d = F.leaky_relu(self.norm3(self.conv3(d)))\n",
    "#         d = F.leaky_relu(self.norm4(self.conv4(d)))\n",
    "        d = F.sigmoid(self.conv3(d))\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_b = Generator(513, 128, 64, 4)\n",
    "gen_b_a = Generator(128, 513, 64, 4)\n",
    "disc_a = Discriminator(513)\n",
    "disc_b = Discriminator(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_gen = torch.optim.Adam(chain(gen_a_b.parameters(), gen_b_a.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_disc_a = torch.optim.Adam(disc_a.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_disc_b = torch.optim.Adam(disc_b.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = get_torch_device()\n",
    "\n",
    "conf = Configuration(audio_dir='/home/kureta/Music/Beethoven Piano Sonatas Barenboim/small/',\n",
    "                     midi_dir='/home/kureta/Music/midi/beethoven/small/')\n",
    "\n",
    "dataset_a = TemporalDataset(conf=conf, example_length=32, example_hop_length=4)\n",
    "data_loader_a = DataLoader(dataset_a, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "dataset_b = TemporalMidiDataset(conf=conf, example_length=32, example_hop_length=4)\n",
    "data_loader_b = DataLoader(dataset_b, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_b.train()\n",
    "gen_b_a.train()\n",
    "disc_a.train()\n",
    "disc_b.train()\n",
    "gen_a_b.to(DEVICE)\n",
    "gen_b_a.to(DEVICE)\n",
    "disc_a.to(DEVICE)\n",
    "disc_b.to(DEVICE)\n",
    "\n",
    "\n",
    "sizes = [8, 16, 32, 64]\n",
    "for i, size in enumerate(sizes):\n",
    "    dataset_a.example_length = size\n",
    "    dataset_b.example_length = size\n",
    "    dataset_a.example_hop_length = size // 2\n",
    "    dataset_b.example_hop_length = size // 2\n",
    "    step = 0\n",
    "    \n",
    "    for example_a, example_b in zip(data_loader_a, data_loader_b):\n",
    "        example_a = example_a.to(DEVICE)\n",
    "        example_b = example_b.to(DEVICE)\n",
    "        \n",
    "        optimizer_gen.zero_grad()\n",
    "        \n",
    "        # Identity loss\n",
    "#         a_id = gen_b_a(example_a)\n",
    "#         b_id = gen_a_b(example_b)\n",
    "#         loss_id = criterion_identity(example_a, a_id) + criterion_identity(example_b, b_id)\n",
    "        \n",
    "        # GAN loss\n",
    "        a_hat = gen_b_a(example_b)\n",
    "        b_hat = gen_a_b(example_a)\n",
    "#         with torch.no_grad():\n",
    "        is_fake_a = disc_a(a_hat)\n",
    "        is_fake_b = disc_b(b_hat)\n",
    "        loss_GAN = criterion_GAN(is_fake_a, torch.ones_like(is_fake_a)) + criterion_GAN(is_fake_b, torch.ones_like(is_fake_b))\n",
    "        \n",
    "        # Cycle loss\n",
    "        cycled_a = gen_b_a(b_hat)\n",
    "        cycled_b = gen_a_b(a_hat)\n",
    "        loss_cycle = criterion_cycle(cycled_a, example_a) + criterion_cycle(cycled_b, example_b)\n",
    "        \n",
    "        # Total generator loss\n",
    "        # loss_gen = 0.5 * loss_id + 10.0 * loss_cycle + loss_GAN\n",
    "        loss_gen = 10.0 * loss_cycle + loss_GAN\n",
    "        loss_gen.backward(retain_graph=True)\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            # optimize generators\n",
    "            optimizer_gen.step()\n",
    "\n",
    "            optimizer_disc_a.zero_grad()\n",
    "\n",
    "            # Disc A loss\n",
    "            is_real_a = disc_a(example_a)\n",
    "    #         is_fake_a = disc_a(a_hat.unsqueeze(1))\n",
    "            loss_disc_a = criterion_GAN(is_real_a, torch.ones_like(is_real_a)) + criterion_GAN(is_fake_a, torch.zeros_like(is_fake_a))\n",
    "            loss_disc_a.backward()\n",
    "\n",
    "            # Optimize Discriminator A\n",
    "            optimizer_disc_a.step()\n",
    "\n",
    "            optimizer_disc_b.zero_grad()\n",
    "\n",
    "            # Disc B loss\n",
    "            is_real_b = disc_b(example_b)\n",
    "    #         is_fake_b = disc_b(b_hat.unsqueeze(1))\n",
    "            loss_disc_b = criterion_GAN(is_real_b, torch.ones_like(is_real_b)) + criterion_GAN(is_fake_b, torch.zeros_like(is_fake_b))\n",
    "            loss_disc_b.backward()\n",
    "\n",
    "            # Optimize Discriminator B\n",
    "            optimizer_disc_b.step()\n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            print(f'({size}) iteration: {step}/{dataset_b.midi.shape[0]}, generator_loss: {loss_gen:.4e}, cycle_loss: {loss_cycle:.4e}, '\n",
    "                  f'gan_loss: {loss_GAN:.4e}, disc_loss: {loss_disc_a + loss_disc_b:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_signal(S, num_iters=15):\n",
    "    # Retrieve phase information\n",
    "    phase = 2 * np.pi * np.random.random_sample(S.shape) - np.pi\n",
    "    signal = None\n",
    "    for idx in range(num_iters):\n",
    "        D = S * np.exp(1j * phase)\n",
    "        signal = librosa.istft(D, hop_length=conf.hop_length, win_length=conf.frame_length)\n",
    "        # don't calculate phase during the last iteration, because it will not be used.\n",
    "        if idx < num_iters - 1:\n",
    "            phase = np.angle(librosa.stft(signal, n_fft=conf.frame_length, hop_length=conf.hop_length))\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_a = '/home/kureta/Music/Beethoven Piano Sonatas Barenboim/split-track01.ape'\n",
    "path_b = '/home/kureta/Music/midi/beethoven/small/appass_1.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zachary.preprocess.base import load_midi_file, trim_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_a = load_audio_file(path_a, conf)\n",
    "midi_b = load_midi_file(path_b, conf)\n",
    "midi_b = trim_zeros(midi_b).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_a, rate=conf.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(midi_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_a = torch.from_numpy(librosa.amplitude_to_db(spectrum_from_signal(audio_a, conf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(spectrum_a.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_b.eval()\n",
    "with torch.no_grad():\n",
    "    midi_b_hat = gen_a_b(spectrum_a.transpose(0, 1).unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(midi_b_hat.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_b_hat.min(), midi_b_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_b_a.eval()\n",
    "with torch.no_grad():\n",
    "    spectrum_a_hat = gen_b_a(torch.from_numpy(midi_b).transpose(0, 1).unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(spectrum_a_hat.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spectrum_a_hat.squeeze(0)[:, :1000].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_a_hat = stft_to_signal(librosa.db_to_amplitude(s.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_a_hat, rate=conf.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachary-venv",
   "language": "python",
   "name": "zachary-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
